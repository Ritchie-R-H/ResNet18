Loading data...
Mean: [0.49261177 0.48097432 0.44712296]
Std: [0.24925695 0.24605115 0.2630386 ]
Loaded CIFAR-10: 60000 train, 10000 test samples.
Data loaded successfully.
Loading model...
Model loaded successfully.
Using device: cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             864
       BatchNorm2d-2           [-1, 32, 32, 32]              64
              SiLU-3           [-1, 32, 32, 32]               0
            Conv2d-4           [-1, 64, 32, 32]          18,432
       BatchNorm2d-5           [-1, 64, 32, 32]             128
            Conv2d-6           [-1, 64, 32, 32]          36,864
           Dropout-7           [-1, 64, 32, 32]               0
       BatchNorm2d-8           [-1, 64, 32, 32]             128
 AdaptiveAvgPool2d-9             [-1, 64, 1, 1]               0
           Conv1d-10                [-1, 1, 64]               3
          Sigmoid-11                   [-1, 64]               0
              ECA-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]           2,048
      BatchNorm2d-14           [-1, 64, 32, 32]             128
 ECAResidualBlock-15           [-1, 64, 32, 32]               0
           Conv2d-16           [-1, 64, 32, 32]          36,864
      BatchNorm2d-17           [-1, 64, 32, 32]             128
           Conv2d-18           [-1, 64, 32, 32]          36,864
          Dropout-19           [-1, 64, 32, 32]               0
      BatchNorm2d-20           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0
           Conv1d-22                [-1, 1, 64]               3
          Sigmoid-23                   [-1, 64]               0
              ECA-24           [-1, 64, 32, 32]               0
 ECAResidualBlock-25           [-1, 64, 32, 32]               0
           Conv2d-26           [-1, 64, 32, 32]          36,864
      BatchNorm2d-27           [-1, 64, 32, 32]             128
           Conv2d-28           [-1, 64, 32, 32]          36,864
          Dropout-29           [-1, 64, 32, 32]               0
      BatchNorm2d-30           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-31             [-1, 64, 1, 1]               0
           Conv1d-32                [-1, 1, 64]               3
          Sigmoid-33                   [-1, 64]               0
              ECA-34           [-1, 64, 32, 32]               0
 ECAResidualBlock-35           [-1, 64, 32, 32]               0
        MaxPool2d-36           [-1, 64, 31, 31]               0
           Conv2d-37          [-1, 128, 16, 16]          73,728
      BatchNorm2d-38          [-1, 128, 16, 16]             256
           Conv2d-39          [-1, 128, 16, 16]         147,456
          Dropout-40          [-1, 128, 16, 16]               0
      BatchNorm2d-41          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-42            [-1, 128, 1, 1]               0
           Conv1d-43               [-1, 1, 128]               3
          Sigmoid-44                  [-1, 128]               0
              ECA-45          [-1, 128, 16, 16]               0
           Conv2d-46          [-1, 128, 16, 16]           8,192
      BatchNorm2d-47          [-1, 128, 16, 16]             256
 ECAResidualBlock-48          [-1, 128, 16, 16]               0
           Conv2d-49          [-1, 128, 16, 16]         147,456
      BatchNorm2d-50          [-1, 128, 16, 16]             256
           Conv2d-51          [-1, 128, 16, 16]         147,456
          Dropout-52          [-1, 128, 16, 16]               0
      BatchNorm2d-53          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-54            [-1, 128, 1, 1]               0
           Conv1d-55               [-1, 1, 128]               3
          Sigmoid-56                  [-1, 128]               0
              ECA-57          [-1, 128, 16, 16]               0
 ECAResidualBlock-58          [-1, 128, 16, 16]               0
        MaxPool2d-59          [-1, 128, 15, 15]               0
           Conv2d-60            [-1, 256, 8, 8]         294,912
      BatchNorm2d-61            [-1, 256, 8, 8]             512
           Conv2d-62            [-1, 256, 8, 8]         589,824
          Dropout-63            [-1, 256, 8, 8]               0
      BatchNorm2d-64            [-1, 256, 8, 8]             512
AdaptiveAvgPool2d-65            [-1, 256, 1, 1]               0
           Conv1d-66               [-1, 1, 256]               3
          Sigmoid-67                  [-1, 256]               0
              ECA-68            [-1, 256, 8, 8]               0
           Conv2d-69            [-1, 256, 8, 8]          32,768
      BatchNorm2d-70            [-1, 256, 8, 8]             512
 ECAResidualBlock-71            [-1, 256, 8, 8]               0
        MaxPool2d-72            [-1, 256, 7, 7]               0
           Conv2d-73            [-1, 480, 4, 4]       1,105,920
      BatchNorm2d-74            [-1, 480, 4, 4]             960
           Conv2d-75            [-1, 480, 4, 4]       2,073,600
          Dropout-76            [-1, 480, 4, 4]               0
      BatchNorm2d-77            [-1, 480, 4, 4]             960
AdaptiveAvgPool2d-78            [-1, 480, 1, 1]               0
           Conv1d-79               [-1, 1, 480]               3
          Sigmoid-80                  [-1, 480]               0
              ECA-81            [-1, 480, 4, 4]               0
           Conv2d-82            [-1, 480, 4, 4]         122,880
      BatchNorm2d-83            [-1, 480, 4, 4]             960
 ECAResidualBlock-84            [-1, 480, 4, 4]               0
AdaptiveAvgPool2d-85            [-1, 480, 1, 1]               0
           Linear-86                   [-1, 10]           4,810
================================================================
Total params: 4,961,343
Trainable params: 4,961,343
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.72
Params size (MB): 18.93
Estimated Total Size (MB): 37.66
----------------------------------------------------------------
                                                                                                                                                                                                                                                         
Epoch [1/50], Loss: 1.4680, Accuracy: 47.30%
Test Accuracy: 58.78%
New best model saved with accuracy 58.78%
Epoch [2/50], Loss: 0.9886, Accuracy: 65.03%
Test Accuracy: 70.29%
New best model saved with accuracy 70.29%
Epoch [3/50], Loss: 0.8172, Accuracy: 71.28%
Test Accuracy: 73.90%
New best model saved with accuracy 73.90%
Epoch [4/50], Loss: 0.7197, Accuracy: 74.89%
Test Accuracy: 74.25%
New best model saved with accuracy 74.25%
Epoch [5/50], Loss: 0.6688, Accuracy: 76.78%
Test Accuracy: 72.80%
Epoch [6/50], Loss: 0.6426, Accuracy: 77.75%
Test Accuracy: 75.55%
New best model saved with accuracy 75.55%
Epoch [7/50], Loss: 0.6142, Accuracy: 78.74%
Test Accuracy: 78.26%
New best model saved with accuracy 78.26%
Epoch [8/50], Loss: 0.5910, Accuracy: 79.46%
Test Accuracy: 77.81%
Epoch [9/50], Loss: 0.5729, Accuracy: 80.11%
Test Accuracy: 77.53%
Epoch [10/50], Loss: 0.5650, Accuracy: 80.37%
Test Accuracy: 79.56%
New best model saved with accuracy 79.56%
Epoch [11/50], Loss: 0.5473, Accuracy: 81.03%
Test Accuracy: 81.52%
New best model saved with accuracy 81.52%
Epoch [12/50], Loss: 0.5320, Accuracy: 81.52%
Test Accuracy: 81.34%
Epoch [13/50], Loss: 0.5211, Accuracy: 81.89%
Test Accuracy: 80.22%
Epoch [14/50], Loss: 0.5105, Accuracy: 82.29%
Test Accuracy: 83.12%
New best model saved with accuracy 83.12%
Epoch [15/50], Loss: 0.5001, Accuracy: 82.83%
Test Accuracy: 83.49%
New best model saved with accuracy 83.49%
Epoch [16/50], Loss: 0.4899, Accuracy: 82.97%
Test Accuracy: 86.24%
New best model saved with accuracy 86.24%
Epoch [17/50], Loss: 0.4745, Accuracy: 83.63%
Test Accuracy: 81.43%
Epoch [18/50], Loss: 0.4701, Accuracy: 83.76%
Test Accuracy: 78.70%
Epoch [19/50], Loss: 0.4634, Accuracy: 84.03%
Test Accuracy: 83.51%
Epoch [20/50], Loss: 0.4474, Accuracy: 84.45%
Test Accuracy: 85.07%
Epoch [21/50], Loss: 0.4401, Accuracy: 84.77%
Test Accuracy: 83.10%
Epoch [22/50], Loss: 0.4278, Accuracy: 85.18%
Test Accuracy: 83.63%
Epoch [23/50], Loss: 0.4156, Accuracy: 85.66%
Test Accuracy: 81.25%
Epoch [24/50], Loss: 0.4085, Accuracy: 85.95%
Test Accuracy: 86.37%
New best model saved with accuracy 86.37%
Epoch [25/50], Loss: 0.3987, Accuracy: 86.24%
Test Accuracy: 84.21%
Epoch [26/50], Loss: 0.3896, Accuracy: 86.53%
Test Accuracy: 86.95%
New best model saved with accuracy 86.95%
Epoch [27/50], Loss: 0.3760, Accuracy: 87.02%
Test Accuracy: 86.34%
Epoch [28/50], Loss: 0.3589, Accuracy: 87.48%
Test Accuracy: 87.05%
New best model saved with accuracy 87.05%
Epoch [29/50], Loss: 0.3548, Accuracy: 87.75%
Test Accuracy: 88.16%
New best model saved with accuracy 88.16%
Epoch [30/50], Loss: 0.3408, Accuracy: 88.28%
Test Accuracy: 88.45%
New best model saved with accuracy 88.45%
Epoch [31/50], Loss: 0.3277, Accuracy: 88.73%
Test Accuracy: 88.55%
New best model saved with accuracy 88.55%
Epoch [32/50], Loss: 0.3133, Accuracy: 89.13%
Test Accuracy: 87.42%
Epoch [33/50], Loss: 0.3028, Accuracy: 89.55%
Test Accuracy: 88.32%
Epoch [34/50], Loss: 0.2879, Accuracy: 90.17%
Test Accuracy: 89.45%
New best model saved with accuracy 89.45%
Epoch [35/50], Loss: 0.2712, Accuracy: 90.69%
Test Accuracy: 89.38%
Epoch [36/50], Loss: 0.2571, Accuracy: 91.11%
Test Accuracy: 90.11%
New best model saved with accuracy 90.11%
Epoch [37/50], Loss: 0.2443, Accuracy: 91.52%
Test Accuracy: 90.95%
New best model saved with accuracy 90.95%
Epoch [38/50], Loss: 0.2284, Accuracy: 92.19%
Test Accuracy: 90.04%
Epoch [39/50], Loss: 0.2178, Accuracy: 92.51%
Test Accuracy: 90.91%
Epoch [40/50], Loss: 0.1964, Accuracy: 93.27%
Test Accuracy: 91.70%
New best model saved with accuracy 91.70%
Epoch [41/50], Loss: 0.1820, Accuracy: 93.72%
Test Accuracy: 92.55%
New best model saved with accuracy 92.55%
Epoch [42/50], Loss: 0.1670, Accuracy: 94.21%
Test Accuracy: 92.35%
Epoch [43/50], Loss: 0.1568, Accuracy: 94.66%
Test Accuracy: 92.52%
Epoch [44/50], Loss: 0.1422, Accuracy: 95.28%
Test Accuracy: 92.85%
New best model saved with accuracy 92.85%
Epoch [45/50], Loss: 0.1317, Accuracy: 95.63%
Test Accuracy: 93.15%
New best model saved with accuracy 93.15%
Epoch [46/50], Loss: 0.1201, Accuracy: 96.04%
Test Accuracy: 93.15%
Epoch [47/50], Loss: 0.1146, Accuracy: 96.16%
Test Accuracy: 93.28%
New best model saved with accuracy 93.28%
Epoch [48/50], Loss: 0.1078, Accuracy: 96.47%
Test Accuracy: 93.38%
New best model saved with accuracy 93.38%
Epoch [49/50], Loss: 0.1061, Accuracy: 96.52%
Test Accuracy: 93.42%
New best model saved with accuracy 93.42%
Epoch [50/50], Loss: 0.1056, Accuracy: 96.56%
Test Accuracy: 93.45%
New best model saved with accuracy 93.45%
Finished Training
