Loading data...
Mean: [0.49261177 0.48097432 0.44712296]
Std: [0.24925695 0.24605115 0.2630386 ]
Loaded CIFAR-10: 60000 train, 10000 test samples.
Data loaded successfully.
Loading model...
Model loaded successfully.
Using device: cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             864
       BatchNorm2d-2           [-1, 32, 32, 32]              64
              SiLU-3           [-1, 32, 32, 32]               0
            Conv2d-4           [-1, 64, 32, 32]          18,432
       BatchNorm2d-5           [-1, 64, 32, 32]             128
            Conv2d-6           [-1, 64, 32, 32]          36,864
           Dropout-7           [-1, 64, 32, 32]               0
       BatchNorm2d-8           [-1, 64, 32, 32]             128
 AdaptiveAvgPool2d-9             [-1, 64, 1, 1]               0
           Conv1d-10                [-1, 1, 64]               3
          Sigmoid-11                   [-1, 64]               0
              ECA-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]           2,048
      BatchNorm2d-14           [-1, 64, 32, 32]             128
 ECAResidualBlock-15           [-1, 64, 32, 32]               0
           Conv2d-16           [-1, 64, 32, 32]          36,864
      BatchNorm2d-17           [-1, 64, 32, 32]             128
           Conv2d-18           [-1, 64, 32, 32]          36,864
          Dropout-19           [-1, 64, 32, 32]               0
      BatchNorm2d-20           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0
           Conv1d-22                [-1, 1, 64]               3
          Sigmoid-23                   [-1, 64]               0
              ECA-24           [-1, 64, 32, 32]               0
 ECAResidualBlock-25           [-1, 64, 32, 32]               0
           Conv2d-26           [-1, 64, 32, 32]          36,864
      BatchNorm2d-27           [-1, 64, 32, 32]             128
           Conv2d-28           [-1, 64, 32, 32]          36,864
          Dropout-29           [-1, 64, 32, 32]               0
      BatchNorm2d-30           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-31             [-1, 64, 1, 1]               0
           Conv1d-32                [-1, 1, 64]               3
          Sigmoid-33                   [-1, 64]               0
              ECA-34           [-1, 64, 32, 32]               0
 ECAResidualBlock-35           [-1, 64, 32, 32]               0
        MaxPool2d-36           [-1, 64, 31, 31]               0
           Conv2d-37          [-1, 128, 16, 16]          73,728
      BatchNorm2d-38          [-1, 128, 16, 16]             256
           Conv2d-39          [-1, 128, 16, 16]         147,456
          Dropout-40          [-1, 128, 16, 16]               0
      BatchNorm2d-41          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-42            [-1, 128, 1, 1]               0
           Conv1d-43               [-1, 1, 128]               3
          Sigmoid-44                  [-1, 128]               0
              ECA-45          [-1, 128, 16, 16]               0
           Conv2d-46          [-1, 128, 16, 16]           8,192
      BatchNorm2d-47          [-1, 128, 16, 16]             256
 ECAResidualBlock-48          [-1, 128, 16, 16]               0
           Conv2d-49          [-1, 128, 16, 16]         147,456
      BatchNorm2d-50          [-1, 128, 16, 16]             256
           Conv2d-51          [-1, 128, 16, 16]         147,456
          Dropout-52          [-1, 128, 16, 16]               0
      BatchNorm2d-53          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-54            [-1, 128, 1, 1]               0
           Conv1d-55               [-1, 1, 128]               3
          Sigmoid-56                  [-1, 128]               0
              ECA-57          [-1, 128, 16, 16]               0
 ECAResidualBlock-58          [-1, 128, 16, 16]               0
        MaxPool2d-59          [-1, 128, 15, 15]               0
           Conv2d-60            [-1, 256, 8, 8]         294,912
      BatchNorm2d-61            [-1, 256, 8, 8]             512
           Conv2d-62            [-1, 256, 8, 8]         589,824
          Dropout-63            [-1, 256, 8, 8]               0
      BatchNorm2d-64            [-1, 256, 8, 8]             512
AdaptiveAvgPool2d-65            [-1, 256, 1, 1]               0
           Conv1d-66               [-1, 1, 256]               3
          Sigmoid-67                  [-1, 256]               0
              ECA-68            [-1, 256, 8, 8]               0
           Conv2d-69            [-1, 256, 8, 8]          32,768
      BatchNorm2d-70            [-1, 256, 8, 8]             512
 ECAResidualBlock-71            [-1, 256, 8, 8]               0
        MaxPool2d-72            [-1, 256, 7, 7]               0
           Conv2d-73            [-1, 480, 4, 4]       1,105,920
      BatchNorm2d-74            [-1, 480, 4, 4]             960
           Conv2d-75            [-1, 480, 4, 4]       2,073,600
          Dropout-76            [-1, 480, 4, 4]               0
      BatchNorm2d-77            [-1, 480, 4, 4]             960
AdaptiveAvgPool2d-78            [-1, 480, 1, 1]               0
           Conv1d-79               [-1, 1, 480]               3
          Sigmoid-80                  [-1, 480]               0
              ECA-81            [-1, 480, 4, 4]               0
           Conv2d-82            [-1, 480, 4, 4]         122,880
      BatchNorm2d-83            [-1, 480, 4, 4]             960
 ECAResidualBlock-84            [-1, 480, 4, 4]               0
AdaptiveAvgPool2d-85            [-1, 480, 1, 1]               0
           Linear-86                   [-1, 10]           4,810
================================================================
Total params: 4,961,343
Trainable params: 4,961,343
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.72
Params size (MB): 18.93
Estimated Total Size (MB): 37.66
----------------------------------------------------------------
Traceback (most recent call last):                                                                                                                                                                                                              
  File "c:\Users\Kang\Learning\25Spring_dl\Project1\train.py", line 184, in <module>
    train_model()
  File "c:\Users\Kang\Learning\25Spring_dl\Project1\train.py", line 104, in train_model
    soft_loss = criterion(student_softmax, teacher_softmax)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Kang\miniconda3\envs\7773\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Kang\miniconda3\envs\7773\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Kang\miniconda3\envs\7773\Lib\site-packages\torch\nn\modules\loss.py", line 1295, in forward
    return F.cross_entropy(
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Kang\miniconda3\envs\7773\Lib\site-packages\torch\nn\functional.py", line 3494, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Expected input batch_size (128) to match target batch_size (50000).
