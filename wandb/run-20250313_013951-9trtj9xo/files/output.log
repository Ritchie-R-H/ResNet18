Loading data...
Mean: [0.49186847 0.48265514 0.44717732]
Std: [0.24697156 0.2433889  0.2615925 ]
Loaded CIFAR-10: 50000 train, 10000 test samples.
Data loaded successfully.
Loading model...
Model loaded successfully.
Using device: cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             864
       BatchNorm2d-2           [-1, 32, 32, 32]              64
              SiLU-3           [-1, 32, 32, 32]               0
            Conv2d-4           [-1, 64, 32, 32]          18,432
       BatchNorm2d-5           [-1, 64, 32, 32]             128
            Conv2d-6           [-1, 64, 32, 32]          36,864
           Dropout-7           [-1, 64, 32, 32]               0
       BatchNorm2d-8           [-1, 64, 32, 32]             128
 AdaptiveAvgPool2d-9             [-1, 64, 1, 1]               0
           Conv1d-10                [-1, 1, 64]               3
          Sigmoid-11                   [-1, 64]               0
              ECA-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]           2,048
      BatchNorm2d-14           [-1, 64, 32, 32]             128
 ECAResidualBlock-15           [-1, 64, 32, 32]               0
           Conv2d-16           [-1, 64, 32, 32]          36,864
      BatchNorm2d-17           [-1, 64, 32, 32]             128
           Conv2d-18           [-1, 64, 32, 32]          36,864
          Dropout-19           [-1, 64, 32, 32]               0
      BatchNorm2d-20           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0
           Conv1d-22                [-1, 1, 64]               3
          Sigmoid-23                   [-1, 64]               0
              ECA-24           [-1, 64, 32, 32]               0
 ECAResidualBlock-25           [-1, 64, 32, 32]               0
           Conv2d-26           [-1, 64, 32, 32]          36,864
      BatchNorm2d-27           [-1, 64, 32, 32]             128
           Conv2d-28           [-1, 64, 32, 32]          36,864
          Dropout-29           [-1, 64, 32, 32]               0
      BatchNorm2d-30           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-31             [-1, 64, 1, 1]               0
           Conv1d-32                [-1, 1, 64]               3
          Sigmoid-33                   [-1, 64]               0
              ECA-34           [-1, 64, 32, 32]               0
 ECAResidualBlock-35           [-1, 64, 32, 32]               0
        MaxPool2d-36           [-1, 64, 31, 31]               0
           Conv2d-37          [-1, 128, 16, 16]          73,728
      BatchNorm2d-38          [-1, 128, 16, 16]             256
           Conv2d-39          [-1, 128, 16, 16]         147,456
          Dropout-40          [-1, 128, 16, 16]               0
      BatchNorm2d-41          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-42            [-1, 128, 1, 1]               0
           Conv1d-43               [-1, 1, 128]               3
          Sigmoid-44                  [-1, 128]               0
              ECA-45          [-1, 128, 16, 16]               0
           Conv2d-46          [-1, 128, 16, 16]           8,192
      BatchNorm2d-47          [-1, 128, 16, 16]             256
 ECAResidualBlock-48          [-1, 128, 16, 16]               0
           Conv2d-49          [-1, 128, 16, 16]         147,456
      BatchNorm2d-50          [-1, 128, 16, 16]             256
           Conv2d-51          [-1, 128, 16, 16]         147,456
          Dropout-52          [-1, 128, 16, 16]               0
      BatchNorm2d-53          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-54            [-1, 128, 1, 1]               0
           Conv1d-55               [-1, 1, 128]               3
          Sigmoid-56                  [-1, 128]               0
              ECA-57          [-1, 128, 16, 16]               0
 ECAResidualBlock-58          [-1, 128, 16, 16]               0
        MaxPool2d-59          [-1, 128, 15, 15]               0
           Conv2d-60            [-1, 256, 8, 8]         294,912
      BatchNorm2d-61            [-1, 256, 8, 8]             512
           Conv2d-62            [-1, 256, 8, 8]         589,824
          Dropout-63            [-1, 256, 8, 8]               0
      BatchNorm2d-64            [-1, 256, 8, 8]             512
AdaptiveAvgPool2d-65            [-1, 256, 1, 1]               0
           Conv1d-66               [-1, 1, 256]               3
          Sigmoid-67                  [-1, 256]               0
              ECA-68            [-1, 256, 8, 8]               0
           Conv2d-69            [-1, 256, 8, 8]          32,768
      BatchNorm2d-70            [-1, 256, 8, 8]             512
 ECAResidualBlock-71            [-1, 256, 8, 8]               0
        MaxPool2d-72            [-1, 256, 7, 7]               0
           Conv2d-73            [-1, 480, 4, 4]       1,105,920
      BatchNorm2d-74            [-1, 480, 4, 4]             960
           Conv2d-75            [-1, 480, 4, 4]       2,073,600
          Dropout-76            [-1, 480, 4, 4]               0
      BatchNorm2d-77            [-1, 480, 4, 4]             960
AdaptiveAvgPool2d-78            [-1, 480, 1, 1]               0
           Conv1d-79               [-1, 1, 480]               3
          Sigmoid-80                  [-1, 480]               0
              ECA-81            [-1, 480, 4, 4]               0
           Conv2d-82            [-1, 480, 4, 4]         122,880
      BatchNorm2d-83            [-1, 480, 4, 4]             960
 ECAResidualBlock-84            [-1, 480, 4, 4]               0
AdaptiveAvgPool2d-85            [-1, 480, 1, 1]               0
           Linear-86                   [-1, 10]           4,810
================================================================
Total params: 4,961,343
Trainable params: 4,961,343
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.72
Params size (MB): 18.93
Estimated Total Size (MB): 37.66
----------------------------------------------------------------
teacher_softmax shape: torch.Size([50000, 10])
trainloader dataset shape: 50000
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:30<00:00, 12.68it/s]
Epoch [1/50], Loss: 1.5347, Accuracy: 49.10%
Test Accuracy: 60.93%
New best model saved with accuracy 60.93%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:30<00:00, 12.80it/s]
Epoch [2/50], Loss: 1.3041, Accuracy: 68.92%
Test Accuracy: 66.80%
New best model saved with accuracy 66.80%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:30<00:00, 12.72it/s]
Epoch [3/50], Loss: 1.2212, Accuracy: 75.97%
Test Accuracy: 76.59%
New best model saved with accuracy 76.59%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:31<00:00, 12.57it/s]
Epoch [4/50], Loss: 1.1871, Accuracy: 78.66%
Test Accuracy: 71.34%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:30<00:00, 12.74it/s]
Epoch [5/50], Loss: 1.1602, Accuracy: 80.66%
Test Accuracy: 74.56%
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 189/391 [00:15<00:15, 12.74it/s]
