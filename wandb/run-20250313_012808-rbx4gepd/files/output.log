Loading data...
Mean: [0.49186847 0.48265514 0.44717732]
Std: [0.24697156 0.2433889  0.2615925 ]
Loaded CIFAR-10: 50000 train, 10000 test samples.
Data loaded successfully.
Loading model...
Model loaded successfully.
Using device: cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             864
       BatchNorm2d-2           [-1, 32, 32, 32]              64
              SiLU-3           [-1, 32, 32, 32]               0
            Conv2d-4           [-1, 64, 32, 32]          18,432
       BatchNorm2d-5           [-1, 64, 32, 32]             128
            Conv2d-6           [-1, 64, 32, 32]          36,864
           Dropout-7           [-1, 64, 32, 32]               0
       BatchNorm2d-8           [-1, 64, 32, 32]             128
 AdaptiveAvgPool2d-9             [-1, 64, 1, 1]               0
           Conv1d-10                [-1, 1, 64]               3
          Sigmoid-11                   [-1, 64]               0
              ECA-12           [-1, 64, 32, 32]               0
           Conv2d-13           [-1, 64, 32, 32]           2,048
      BatchNorm2d-14           [-1, 64, 32, 32]             128
 ECAResidualBlock-15           [-1, 64, 32, 32]               0
           Conv2d-16           [-1, 64, 32, 32]          36,864
      BatchNorm2d-17           [-1, 64, 32, 32]             128
           Conv2d-18           [-1, 64, 32, 32]          36,864
          Dropout-19           [-1, 64, 32, 32]               0
      BatchNorm2d-20           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-21             [-1, 64, 1, 1]               0
           Conv1d-22                [-1, 1, 64]               3
          Sigmoid-23                   [-1, 64]               0
              ECA-24           [-1, 64, 32, 32]               0
 ECAResidualBlock-25           [-1, 64, 32, 32]               0
           Conv2d-26           [-1, 64, 32, 32]          36,864
      BatchNorm2d-27           [-1, 64, 32, 32]             128
           Conv2d-28           [-1, 64, 32, 32]          36,864
          Dropout-29           [-1, 64, 32, 32]               0
      BatchNorm2d-30           [-1, 64, 32, 32]             128
AdaptiveAvgPool2d-31             [-1, 64, 1, 1]               0
           Conv1d-32                [-1, 1, 64]               3
          Sigmoid-33                   [-1, 64]               0
              ECA-34           [-1, 64, 32, 32]               0
 ECAResidualBlock-35           [-1, 64, 32, 32]               0
        MaxPool2d-36           [-1, 64, 31, 31]               0
           Conv2d-37          [-1, 128, 16, 16]          73,728
      BatchNorm2d-38          [-1, 128, 16, 16]             256
           Conv2d-39          [-1, 128, 16, 16]         147,456
          Dropout-40          [-1, 128, 16, 16]               0
      BatchNorm2d-41          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-42            [-1, 128, 1, 1]               0
           Conv1d-43               [-1, 1, 128]               3
          Sigmoid-44                  [-1, 128]               0
              ECA-45          [-1, 128, 16, 16]               0
           Conv2d-46          [-1, 128, 16, 16]           8,192
      BatchNorm2d-47          [-1, 128, 16, 16]             256
 ECAResidualBlock-48          [-1, 128, 16, 16]               0
           Conv2d-49          [-1, 128, 16, 16]         147,456
      BatchNorm2d-50          [-1, 128, 16, 16]             256
           Conv2d-51          [-1, 128, 16, 16]         147,456
          Dropout-52          [-1, 128, 16, 16]               0
      BatchNorm2d-53          [-1, 128, 16, 16]             256
AdaptiveAvgPool2d-54            [-1, 128, 1, 1]               0
           Conv1d-55               [-1, 1, 128]               3
          Sigmoid-56                  [-1, 128]               0
              ECA-57          [-1, 128, 16, 16]               0
 ECAResidualBlock-58          [-1, 128, 16, 16]               0
        MaxPool2d-59          [-1, 128, 15, 15]               0
           Conv2d-60            [-1, 256, 8, 8]         294,912
      BatchNorm2d-61            [-1, 256, 8, 8]             512
           Conv2d-62            [-1, 256, 8, 8]         589,824
          Dropout-63            [-1, 256, 8, 8]               0
      BatchNorm2d-64            [-1, 256, 8, 8]             512
AdaptiveAvgPool2d-65            [-1, 256, 1, 1]               0
           Conv1d-66               [-1, 1, 256]               3
          Sigmoid-67                  [-1, 256]               0
              ECA-68            [-1, 256, 8, 8]               0
           Conv2d-69            [-1, 256, 8, 8]          32,768
      BatchNorm2d-70            [-1, 256, 8, 8]             512
 ECAResidualBlock-71            [-1, 256, 8, 8]               0
        MaxPool2d-72            [-1, 256, 7, 7]               0
           Conv2d-73            [-1, 480, 4, 4]       1,105,920
      BatchNorm2d-74            [-1, 480, 4, 4]             960
           Conv2d-75            [-1, 480, 4, 4]       2,073,600
          Dropout-76            [-1, 480, 4, 4]               0
      BatchNorm2d-77            [-1, 480, 4, 4]             960
AdaptiveAvgPool2d-78            [-1, 480, 1, 1]               0
           Conv1d-79               [-1, 1, 480]               3
          Sigmoid-80                  [-1, 480]               0
              ECA-81            [-1, 480, 4, 4]               0
           Conv2d-82            [-1, 480, 4, 4]         122,880
      BatchNorm2d-83            [-1, 480, 4, 4]             960
 ECAResidualBlock-84            [-1, 480, 4, 4]               0
AdaptiveAvgPool2d-85            [-1, 480, 1, 1]               0
           Linear-86                   [-1, 10]           4,810
================================================================
Total params: 4,961,343
Trainable params: 4,961,343
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 18.72
Params size (MB): 18.93
Estimated Total Size (MB): 37.66
----------------------------------------------------------------
teacher_softmax shape: torch.Size([50000, 10])
trainloader dataset shape: 50000
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:40<00:00,  9.54it/s]
Epoch [1/50], Loss: 1.5161, Accuracy: 50.82%
Test Accuracy: 60.11%
New best model saved with accuracy 60.11%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.89it/s]
Epoch [2/50], Loss: 1.2943, Accuracy: 70.04%
Test Accuracy: 73.82%
New best model saved with accuracy 73.82%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.86it/s]
Epoch [3/50], Loss: 1.2193, Accuracy: 76.20%
Test Accuracy: 75.00%
New best model saved with accuracy 75.00%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.86it/s]
Epoch [4/50], Loss: 1.1801, Accuracy: 79.37%
Test Accuracy: 72.87%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.75it/s]
Epoch [5/50], Loss: 1.1577, Accuracy: 81.05%
Test Accuracy: 78.06%
New best model saved with accuracy 78.06%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.70it/s]
Epoch [6/50], Loss: 1.1437, Accuracy: 82.19%
Test Accuracy: 81.48%
New best model saved with accuracy 81.48%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:30<00:00, 12.63it/s]
Epoch [7/50], Loss: 1.1342, Accuracy: 82.80%
Test Accuracy: 77.76%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:31<00:00, 12.54it/s]
Epoch [8/50], Loss: 1.1249, Accuracy: 83.42%
Test Accuracy: 71.01%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:31<00:00, 12.44it/s]
Epoch [9/50], Loss: 1.1204, Accuracy: 83.70%
Test Accuracy: 83.02%
New best model saved with accuracy 83.02%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:31<00:00, 12.58it/s]
Epoch [10/50], Loss: 1.1106, Accuracy: 84.52%
Test Accuracy: 79.37%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:31<00:00, 12.36it/s]
Epoch [11/50], Loss: 1.1085, Accuracy: 84.56%
Test Accuracy: 81.36%
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:31<00:00, 12.56it/s]
Epoch [12/50], Loss: 1.1021, Accuracy: 85.16%
Test Accuracy: 82.25%
 45%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                             | 175/390 [00:14<00:17, 12.35it/s]
