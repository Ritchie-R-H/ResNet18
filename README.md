The core goal is to achieve the highest possible accuracy on test data while strictly limiting the modelâ€™s parameter count to under 5 million. To address this, we explored structural adjustments such as applying SGD optimization,
optimizing convolutional layer and fully connected layer configurations, experimenting with pooling methods and channel attention. Next, we compare the results obtained on the CIFAR-10 test set with those of our Kaggle-custom test
set.
