{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda62191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb44875",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "       \n",
    "        self.downsample = downsample\n",
    "        if downsample:\n",
    "            self.skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            self.skip_bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.skip_conv = None  # Ensure it's defined\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.skip_bn(self.skip_conv(x))\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity  \n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f62b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        \n",
    "        # Initial Convolution\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Residual layers with variable channels\n",
    "        self.layer1 = self._make_layer(64, 64, num_blocks=2, stride=1)  # No downsampling\n",
    "        self.layer2 = self._make_layer(64, 128, num_blocks=2, stride=2)  # Downsampling\n",
    "        self.layer3 = self._make_layer(128, 256, num_blocks=2, stride=2)  # Downsampling\n",
    "        self.layer4 = self._make_layer(256, 512, num_blocks=2, stride=2)  # Downsampling\n",
    "\n",
    "        # Average Pooling (kernel size = 2, stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride=stride, downsample=True))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b04869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e980e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_batches():\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1, 6):  # data_batch_1 to data_batch_5\n",
    "        batch_file = os.path.join(data_dir, f\"data_batch_{i}\")\n",
    "        batch_dict = unpickle(batch_file)\n",
    "        \n",
    "        batch_data = batch_dict[b'data']  # Image data (10000, 3072)\n",
    "        batch_labels = batch_dict[b'labels']  # Labels (10000,)\n",
    "        \n",
    "        train_data.append(batch_data)\n",
    "        train_labels.extend(batch_labels)\n",
    "    \n",
    "    train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).astype(np.float32) / 255.0  # Normalize\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_data, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ef54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_test():\n",
    "    test_file = os.path.join(data_dir, \"test_batch\")\n",
    "    test_dict = unpickle(test_file)\n",
    "    \n",
    "    test_data = test_dict[b'data'].reshape(-1, 3, 32, 32).astype(np.float32) / 255.0\n",
    "    test_labels = np.array(test_dict[b'labels'])\n",
    "    \n",
    "    return test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85386ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx], self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3548e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"🎯 Test Accuracy: {test_acc:.2f}%\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26c97c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/cifar-10-batches-py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af36126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CIFAR-10: 40000 train, 10000 val, 10000 test samples.\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_data, train_labels = load_cifar10_batches()\n",
    "test_data, test_labels = load_cifar10_test()\n",
    "\n",
    "# Split Training Set into Training & Validation (80% Train, 20% Validation)\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_data, val_data = train_data[:train_size], train_data[train_size:]\n",
    "train_labels, val_labels = train_labels[:train_size], train_labels[train_size:]\n",
    "\n",
    "# Define Data Transformations (Data Augmentation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create Dataset & DataLoader\n",
    "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "val_dataset = CIFAR10Dataset(val_data, val_labels, transform=transform)\n",
    "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Loaded CIFAR-10: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5281c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e1dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Epoch 1/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 1.7790\n",
      "🟢 [Batch 100/313] Loss: 1.6734\n",
      "🟢 [Batch 150/313] Loss: 1.5855\n",
      "🟢 [Batch 200/313] Loss: 1.6657\n",
      "🟢 [Batch 250/313] Loss: 1.3360\n",
      "🟢 [Batch 300/313] Loss: 1.3306\n",
      "🟢 [Batch 313/313] Loss: 1.3427\n",
      "✅ Training Loss: 1.7036, Training Accuracy: 38.93%\n",
      "🔵 Validation Accuracy: 48.29%\n",
      "💾 Best model saved with Validation Accuracy: 48.29%\n",
      "\n",
      "🔄 Epoch 2/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 1.2758\n",
      "🟢 [Batch 100/313] Loss: 1.3269\n",
      "🟢 [Batch 150/313] Loss: 1.3842\n",
      "🟢 [Batch 200/313] Loss: 1.3460\n",
      "🟢 [Batch 250/313] Loss: 1.2879\n",
      "🟢 [Batch 300/313] Loss: 0.9574\n",
      "🟢 [Batch 313/313] Loss: 0.9980\n",
      "✅ Training Loss: 1.1874, Training Accuracy: 57.40%\n",
      "🔵 Validation Accuracy: 58.35%\n",
      "💾 Best model saved with Validation Accuracy: 58.35%\n",
      "\n",
      "🔄 Epoch 3/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 1.1122\n",
      "🟢 [Batch 100/313] Loss: 0.9712\n",
      "🟢 [Batch 150/313] Loss: 0.9172\n",
      "🟢 [Batch 200/313] Loss: 1.1087\n",
      "🟢 [Batch 250/313] Loss: 0.7813\n",
      "🟢 [Batch 300/313] Loss: 0.9815\n",
      "🟢 [Batch 313/313] Loss: 1.0577\n",
      "✅ Training Loss: 0.9602, Training Accuracy: 65.95%\n",
      "🔵 Validation Accuracy: 64.96%\n",
      "💾 Best model saved with Validation Accuracy: 64.96%\n",
      "\n",
      "🔄 Epoch 4/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.8834\n",
      "🟢 [Batch 100/313] Loss: 0.8252\n",
      "🟢 [Batch 150/313] Loss: 0.7659\n",
      "🟢 [Batch 200/313] Loss: 0.8340\n",
      "🟢 [Batch 250/313] Loss: 0.7672\n",
      "🟢 [Batch 300/313] Loss: 0.7628\n",
      "🟢 [Batch 313/313] Loss: 0.6475\n",
      "✅ Training Loss: 0.8129, Training Accuracy: 71.19%\n",
      "🔵 Validation Accuracy: 68.33%\n",
      "💾 Best model saved with Validation Accuracy: 68.33%\n",
      "\n",
      "🔄 Epoch 5/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.7034\n",
      "🟢 [Batch 100/313] Loss: 0.9196\n",
      "🟢 [Batch 150/313] Loss: 0.7505\n",
      "🟢 [Batch 200/313] Loss: 0.6642\n",
      "🟢 [Batch 250/313] Loss: 0.7926\n",
      "🟢 [Batch 300/313] Loss: 0.5801\n",
      "🟢 [Batch 313/313] Loss: 0.6220\n",
      "✅ Training Loss: 0.6928, Training Accuracy: 75.73%\n",
      "🔵 Validation Accuracy: 73.32%\n",
      "💾 Best model saved with Validation Accuracy: 73.32%\n",
      "\n",
      "🔄 Epoch 6/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.4709\n",
      "🟢 [Batch 100/313] Loss: 0.5196\n",
      "🟢 [Batch 150/313] Loss: 0.6371\n",
      "🟢 [Batch 200/313] Loss: 0.6830\n",
      "🟢 [Batch 250/313] Loss: 0.4888\n",
      "🟢 [Batch 300/313] Loss: 0.6821\n",
      "🟢 [Batch 313/313] Loss: 0.4696\n",
      "✅ Training Loss: 0.6061, Training Accuracy: 78.91%\n",
      "🔵 Validation Accuracy: 77.12%\n",
      "💾 Best model saved with Validation Accuracy: 77.12%\n",
      "\n",
      "🔄 Epoch 7/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.5389\n",
      "🟢 [Batch 100/313] Loss: 0.7066\n",
      "🟢 [Batch 150/313] Loss: 0.4710\n",
      "🟢 [Batch 200/313] Loss: 0.5869\n",
      "🟢 [Batch 250/313] Loss: 0.6491\n",
      "🟢 [Batch 300/313] Loss: 0.4147\n",
      "🟢 [Batch 313/313] Loss: 0.3926\n",
      "✅ Training Loss: 0.5470, Training Accuracy: 81.09%\n",
      "🔵 Validation Accuracy: 81.01%\n",
      "💾 Best model saved with Validation Accuracy: 81.01%\n",
      "\n",
      "🔄 Epoch 8/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.3898\n",
      "🟢 [Batch 100/313] Loss: 0.5033\n",
      "🟢 [Batch 150/313] Loss: 0.3924\n",
      "🟢 [Batch 200/313] Loss: 0.4117\n",
      "🟢 [Batch 250/313] Loss: 0.4549\n",
      "🟢 [Batch 300/313] Loss: 0.5779\n",
      "🟢 [Batch 313/313] Loss: 0.3777\n",
      "✅ Training Loss: 0.4932, Training Accuracy: 82.68%\n",
      "🔵 Validation Accuracy: 80.32%\n",
      "\n",
      "🔄 Epoch 9/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.5003\n",
      "🟢 [Batch 100/313] Loss: 0.4274\n",
      "🟢 [Batch 150/313] Loss: 0.4959\n",
      "🟢 [Batch 200/313] Loss: 0.3421\n",
      "🟢 [Batch 250/313] Loss: 0.2628\n",
      "🟢 [Batch 300/313] Loss: 0.5356\n",
      "🟢 [Batch 313/313] Loss: 0.3530\n",
      "✅ Training Loss: 0.4406, Training Accuracy: 84.76%\n",
      "🔵 Validation Accuracy: 82.89%\n",
      "💾 Best model saved with Validation Accuracy: 82.89%\n",
      "\n",
      "🔄 Epoch 10/10 ---------------------------\n",
      "🟢 [Batch 50/313] Loss: 0.4657\n",
      "🟢 [Batch 100/313] Loss: 0.4177\n",
      "🟢 [Batch 150/313] Loss: 0.3356\n",
      "🟢 [Batch 200/313] Loss: 0.3490\n",
      "🟢 [Batch 250/313] Loss: 0.2654\n",
      "🟢 [Batch 300/313] Loss: 0.3732\n",
      "🟢 [Batch 313/313] Loss: 0.2961\n",
      "✅ Training Loss: 0.4072, Training Accuracy: 85.79%\n",
      "🔵 Validation Accuracy: 85.30%\n",
      "💾 Best model saved with Validation Accuracy: 85.30%\n",
      "\n",
      "🎉 Training Completed!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtest\u001b[49m(model, test_loader, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n🔄 Epoch {epoch+1}/{num_epochs} ---------------------------\")\n",
    "    \n",
    "    ### TRAINING PHASE ###\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Print loss for every 50 batches\n",
    "        if (batch_idx + 1) % 50 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print(f\"🟢 [Batch {batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    print(f\"✅ Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    ### VALIDATION PHASE ###\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f\"🔵 Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    ### SAVE BEST MODEL ###\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"💾 Best model saved with Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n🎉 Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "756b8d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Test Accuracy: 84.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3495b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Total Trainable Parameters: 11,193,546\n",
      "❌ Model exceeds 5 million parameters! Consider reducing layers or channels.\n"
     ]
    }
   ],
   "source": [
    "# Function to count model parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"🔢 Total Trainable Parameters: {total_params:,}\")  # Print with commas\n",
    "    return total_params\n",
    "\n",
    "# Check model parameters\n",
    "total_params = count_parameters(model)\n",
    "\n",
    "# Check if model meets the requirement\n",
    "if total_params > 5_000_000:\n",
    "    print(\"❌ Model exceeds 5 million parameters! Consider reducing layers or channels.\")\n",
    "else:\n",
    "    print(\"✅ Model meets the requirement (≤5 million parameters).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7dbe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "     ResidualBlock-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "    ResidualBlock-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "           Conv2d-19          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-21          [-1, 128, 16, 16]               0\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "           Conv2d-24          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-26          [-1, 128, 16, 16]               0\n",
      "           Conv2d-27            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "           Conv2d-31            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-32            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-33            [-1, 256, 8, 8]               0\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "           Conv2d-36            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-37            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-38            [-1, 256, 8, 8]               0\n",
      "           Conv2d-39            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-43            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-45            [-1, 512, 4, 4]               0\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-48            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-49            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-50            [-1, 512, 4, 4]               0\n",
      "        AvgPool2d-51            [-1, 512, 2, 2]               0\n",
      "           Linear-52                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 11,193,546\n",
      "Trainable params: 11,193,546\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 12.27\n",
      "Params size (MB): 42.70\n",
      "Estimated Total Size (MB): 54.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Move model to the correct device (CPU or GPU)\n",
    "model.to(device)\n",
    "\n",
    "# Print model summary (assuming input image size is 3×32×32 for CIFAR-10)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356e75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81364ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf540d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
